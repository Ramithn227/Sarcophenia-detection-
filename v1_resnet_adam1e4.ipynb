{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ec682-aa09-4efb-b06b-031125b248a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import segmentation_models_pytorch as sm\n",
    "\n",
    "# loss_type = \"mse\"\n",
    "loss_type = \"bce\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393e52ef-d57e-459d-a390-bb0bb4952c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "#     transforms.Resize((256, 256)),\n",
    "    transforms.RandomAffine(15, translate=[0.05,0.05], scale=[0.9,1.1]), \n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize( [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize( [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, main_dir, data_dirs, transform):\n",
    "        self.transform = transform\n",
    "        self.main_dir = main_dir\n",
    "        self.total_imgs = data_dirs\n",
    "\n",
    "    def __len__(self): return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        if loss_type == \"mse\":\n",
    "            if \"norm\" in img_loc: \n",
    "                return tensor_image[:1,:,:], torch.Tensor([0]).float()\n",
    "            if \"abn\" in img_loc: \n",
    "                return tensor_image[:1,:,:], torch.Tensor([1]).float()\n",
    "        elif loss_type == \"bce\":\n",
    "            if \"norm\" in img_loc: \n",
    "                return tensor_image[:1,:,:], torch.Tensor([0]).long()\n",
    "            if \"abn\" in img_loc: \n",
    "                return tensor_image[:1,:,:], torch.Tensor([1]).long()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "main_dir = \"./0822data/256png/\"\n",
    "train_dirs, test_dirs = train_test_split(os.listdir(main_dir), test_size = 0.2)\n",
    "\n",
    "train_dataset = CustomDataSet(main_dir, train_dirs, transform = transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset , batch_size=16, shuffle=True, \n",
    "                                           num_workers=4, pin_memory=True, drop_last=True)\n",
    "test_dataset = CustomDataSet(main_dir, test_dirs, transform = transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset , batch_size=16, shuffle=False, \n",
    "                                          num_workers=4, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddefbca-a69c-49ca-a131-dba8be40f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet18(pretrained=True)\n",
    "if loss_type == \"mse\":\n",
    "    model.fc = nn.Linear(512, 1)\n",
    "elif loss_type == \"bce\":\n",
    "    model.fc = nn.Linear(512, 2)\n",
    "device = 'cuda:1'\n",
    "model.to(device)\n",
    "print(\"model is OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f072bb6-1bc8-42fc-82c7-cc6fd28bc94d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if loss_type == \"mse\":\n",
    "    criterion = nn.MSELoss()\n",
    "elif loss_type == \"bce\":\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "model.train()\n",
    "overall_loss = list()\n",
    "overall_acc = list()\n",
    "\n",
    "for iteration in range(50):\n",
    "    \n",
    "    print(iteration)\n",
    "    model.train()\n",
    "    train_loss, train_correct, train_count = 0, 0, 0\n",
    "    for train_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs = inputs.repeat(1,3,1,1)\n",
    "        if loss_type == \"mse\":\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "        elif loss_type == \"bce\":\n",
    "            inputs, targets = inputs.to(device), targets[:,0].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        if loss_type == \"mse\":\n",
    "            train_correct += torch.eq((outputs[:,:1]>0.5)*1, targets).sum().item()\n",
    "        elif loss_type == \"bce\":\n",
    "            pred = F.softmax(outputs, dim=1).argmax(dim=1)\n",
    "            train_correct += torch.eq(pred, targets).sum().item()  # convert to numpy\n",
    "        train_count += len(targets)\n",
    "    \n",
    "    test_loss, test_correct, test_count = 0, 0, 0\n",
    "    model.eval()\n",
    "    for test_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs = inputs.repeat(1,3,1,1)\n",
    "        if loss_type == \"mse\":\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "        elif loss_type == \"bce\":\n",
    "            inputs, targets = inputs.to(device), targets[:,0].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        if loss_type == \"mse\":\n",
    "            test_correct += torch.eq((outputs[:,:1]>0.5)*1, targets).sum().item()\n",
    "        elif loss_type == \"bce\":\n",
    "            pred = F.softmax(outputs, dim=1).argmax(dim=1)\n",
    "            test_correct += torch.eq(pred, targets).sum().item()  # convert to numpy\n",
    "        test_count += len(targets)\n",
    "        \n",
    "    overall_loss.append([train_loss/(train_idx+1), test_loss/(test_idx+1)])\n",
    "    overall_acc.append([train_correct/train_count, test_correct/test_count])\n",
    "    \n",
    "overall_loss = np.array(overall_loss)\n",
    "overall_acc = np.array(overall_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d39a4f-ec79-4cdb-bc48-e8a3554ca0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(overall_loss[:,0], label=\"train loss\")\n",
    "plt.plot(overall_loss[:,1], label=\"test loss\")\n",
    "plt.pause(0.1)\n",
    "plt.plot(overall_acc[:,0], label=\"train acc\")\n",
    "plt.plot(overall_acc[:,1], label=\"test acc\")\n",
    "plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f294e7-0479-4faf-b078-13ba060cd51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
