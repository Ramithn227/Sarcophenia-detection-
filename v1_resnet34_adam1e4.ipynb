{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e17ec682-aa09-4efb-b06b-031125b248a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import segmentation_models_pytorch as sm\n",
    "\n",
    "# loss_type = \"mse\"\n",
    "loss_type = \"bce\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "393e52ef-d57e-459d-a390-bb0bb4952c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "#     transforms.Resize((256, 256)),\n",
    "    transforms.RandomAffine(15, translate=[0.05,0.05], scale=[0.9,1.1]), \n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize( [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize( [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, main_dir, data_dirs, transform):\n",
    "        self.transform = transform\n",
    "        self.main_dir = main_dir\n",
    "        self.total_imgs = data_dirs\n",
    "\n",
    "    def __len__(self): return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        if loss_type == \"mse\":\n",
    "            if \"norm\" in img_loc: \n",
    "                return tensor_image[:1,:,:], torch.Tensor([0]).float()\n",
    "            if \"abn\" in img_loc: \n",
    "                return tensor_image[:1,:,:], torch.Tensor([1]).float()\n",
    "        elif loss_type == \"bce\":\n",
    "            if \"norm\" in img_loc: \n",
    "                return tensor_image[:1,:,:], torch.Tensor([0]).long()\n",
    "            if \"abn\" in img_loc: \n",
    "                return tensor_image[:1,:,:], torch.Tensor([1]).long()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "main_dir = \"./0822data/256png/\"\n",
    "train_dirs, test_dirs = train_test_split(os.listdir(main_dir), test_size = 0.2)\n",
    "\n",
    "train_dataset = CustomDataSet(main_dir, train_dirs, transform = transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset , batch_size=16, shuffle=True, \n",
    "                                           num_workers=4, pin_memory=True, drop_last=True)\n",
    "test_dataset = CustomDataSet(main_dir, test_dirs, transform = transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset , batch_size=16, shuffle=False, \n",
    "                                          num_workers=4, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ddefbca-a69c-49ca-a131-dba8be40f63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\jupiter\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     model\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 8\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel is OK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\jupiter\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[1;32mD:\\jupiter\\Lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\jupiter\\Lib\\site-packages\\torch\\nn\\modules\\module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[0;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mD:\\jupiter\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n",
      "File \u001b[1;32mD:\\jupiter\\Lib\\site-packages\\torch\\cuda\\__init__.py:289\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m     )\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet34(weights=True)\n",
    "if loss_type == \"mse\":\n",
    "    model.fc = nn.Linear(512, 1)\n",
    "elif loss_type == \"bce\":\n",
    "    model.fc = nn.Linear(512, 2)\n",
    "device = 'cuda:1'\n",
    "model.to(device)\n",
    "print(\"model is OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f072bb6-1bc8-42fc-82c7-cc6fd28bc94d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if loss_type == \"mse\":\n",
    "    criterion = nn.MSELoss()\n",
    "elif loss_type == \"bce\":\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "model.train()\n",
    "overall_loss = list()\n",
    "overall_acc = list()\n",
    "\n",
    "for iteration in range(50):\n",
    "    \n",
    "    model.train()\n",
    "    print(iteration)\n",
    "    train_loss, train_correct, train_count = 0, 0, 0\n",
    "    for train_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs = inputs.repeat(1,3,1,1)\n",
    "        if loss_type == \"mse\":\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "        elif loss_type == \"bce\":\n",
    "            inputs, targets = inputs.to(device), targets[:,0].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        if loss_type == \"mse\":\n",
    "            train_correct += torch.eq((outputs[:,:1]>0.5)*1, targets).sum().item()\n",
    "        elif loss_type == \"bce\":\n",
    "            pred = F.softmax(outputs, dim=1).argmax(dim=1)\n",
    "            train_correct += torch.eq(pred, targets).sum().item()  # convert to numpy\n",
    "        train_count += len(targets)\n",
    "    \n",
    "    test_loss, test_correct, test_count = 0, 0, 0\n",
    "    model.eval()\n",
    "    for test_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs = inputs.repeat(1,3,1,1)\n",
    "        if loss_type == \"mse\":\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "        elif loss_type == \"bce\":\n",
    "            inputs, targets = inputs.to(device), targets[:,0].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        if loss_type == \"mse\":\n",
    "            test_correct += torch.eq((outputs[:,:1]>0.5)*1, targets).sum().item()\n",
    "        elif loss_type == \"bce\":\n",
    "            pred = F.softmax(outputs, dim=1).argmax(dim=1)\n",
    "            test_correct += torch.eq(pred, targets).sum().item()  # convert to numpy\n",
    "        test_count += len(targets)\n",
    "        \n",
    "    overall_loss.append([train_loss/(train_idx+1), test_loss/(test_idx+1)])\n",
    "    overall_acc.append([train_correct/train_count, test_correct/test_count])\n",
    "    \n",
    "overall_loss = np.array(overall_loss)\n",
    "overall_acc = np.array(overall_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d39a4f-ec79-4cdb-bc48-e8a3554ca0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(overall_loss[:,0], label=\"train loss\")\n",
    "plt.plot(overall_loss[:,1], label=\"test loss\")\n",
    "plt.pause(0.1)\n",
    "plt.plot(overall_acc[:,0], label=\"train acc\")\n",
    "plt.plot(overall_acc[:,1], label=\"test acc\")\n",
    "plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f294e7-0479-4faf-b078-13ba060cd51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb10c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
